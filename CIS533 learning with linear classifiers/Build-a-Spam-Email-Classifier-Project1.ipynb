{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19eedb2d057408d54e27cffee9f71a54",
     "grade": false,
     "grade_id": "cell-bb88f0a35b56d0ae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>About this Project</h2>\n",
    "\n",
    "**In this project, you will calculate the logistic loss.** In the next projects, you will calculate the gradient of the logistic loss function and implement gradient descent. You will ultimately use all these functions in the final project to create a logistic regression classifier that can \"filter\" spam email messages.\n",
    "\n",
    "<h3>Evaluation</h3>\n",
    "\n",
    "<p><strong>This project must be successfully completed and submitted in order to receive credit for this course. Your score on this project will be included in your final grade calculation.</strong><p>\n",
    "    \n",
    "<p>You are expected to write code where you see <em># YOUR CODE HERE</em> within the cells of this notebook. Not all cells will be graded; code input cells followed by cells marked with <em>#Autograder test cell</em> will be graded. Upon submitting your work, the code you write at these designated positions will be assessed using an \"autograder\" that will run all test cells to assess your code. You will receive feedback from the autograder that will identify any errors in your code. Use this feedback to improve your code if you need to resubmit. Be sure not to change the names of any provided functions, classes, or variables within the existing code cells, as this will interfere with the autograder. Also, remember to execute all code cells sequentially, not just those you’ve edited, to ensure your code runs properly.</p>\n",
    "    \n",
    "<p>You can resubmit your work as many times as necessary before the submission deadline. If you experience difficulty or have questions about this exercise, use the Q&A discussion board (found in the Live Labs section of this course) to engage with your peers or seek assistance from the instructor.<p>\n",
    "\n",
    "<p>Before starting your work, please review <a href=\"https://s3.amazonaws.com/ecornell/global/eCornellPlagiarismPolicy.pdf\">eCornell's policy regarding plagiarism</a> (the presentation of someone else's work as your own without source credit).</p>\n",
    "\n",
    "<h3>Submit Code for Autograder Feedback</h3>\n",
    "\n",
    "<p>Once you have completed your work on this notebook, you will submit your code for autograder review. Follow these steps:</p>\n",
    "\n",
    "<ol>\n",
    "    <li><strong>Save your notebook —</strong> Click <strong>Save and Checkpoint</strong> in the \"File\" menu.</li>\n",
    "  <li><strong>Mark as Completed —</strong> In the blue menu bar along the top of this code exercise window, you’ll see a menu item called <strong>Education</strong>. In the <strong>Education</strong> menu, click <strong>Mark as Completed</strong> to submit your code for autograder/instructor review. This process will take a moment and a progress bar will show you the status of your submission.</li>\n",
    "\t<li><strong>Review your results —</strong> Once your work is marked as complete, the results of the autograder will automatically be presented in a new tab within the code exercise window. You can click on the assessment name in this feedback window to see more details regarding specific feedback/errors in your code submission.</li>\n",
    "  <li><strong>Repeat, if necessary —</strong> The Jupyter notebook will always remain accessible in the first tabbed window of the exercise. To reattempt the work, you will first need to click <strong>Mark as Uncompleted</strong> in the <strong>Education</strong> menu and then proceed to make edits to the notebook. Once you are ready to resubmit, follow steps one through three. You can repeat this procedure as many times as necessary.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a5db60cf2d87cbe7e95ed275d7d6cf9",
     "grade": false,
     "grade_id": "cell-ae461e465b7f800e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Getting Started</h2>\n",
    "<h3>Python Initialization</h3> \n",
    "\n",
    "Please run the following code to initialize your Python kernel. You should be running a version of Python 3.x. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e3c7b9574a10eba8fe3ac62d643ec4da",
     "grade": false,
     "grade_id": "cell-a801a09f2b1fc82b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "\n",
    "from helper import *\n",
    "\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19b0de86145b18d8ae7d8bc7a3807ac3",
     "grade": false,
     "grade_id": "cell-5e40cd81b8f0dd4a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build a Spam Email Classifier - Project 1 (Logistic Loss)\n",
    "\n",
    "Rather than working directly on the email data, we will first build some intuition about logistic regression using random data. Let's approach the spam email classification problem from the end-goal.\n",
    "\n",
    "What will be our inputs and outputs? Our input ultimately will be email text data or metadata, and the classifier should process one email (an input data point) to output 'spam' or 'not spam'. How can we represent the inputs and outputs in a machine-readable form? We can convert text data into a $d$-dimensional numeric vector (such as by using the hashing technique, which you might remember from a previous course). For outputs, we can represent the 'spam' or 'not spam' with binary (-1/1) labels.\n",
    "\n",
    "Since our problem is a binary classification problem on numeric features, we can now abstract away the actual dataset and use an artificial dataset created randomly. For visualization purposes, we will limit ourselves to 2-dimensional feature vector when working with an artificial dataset.\n",
    "\n",
    "One way to generate 2D random data for 2 classes is by using non-overlapping multivariate normal distributions. This should be very easily separable for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "50bf7c52ba1fac3be824599fa0bf602a",
     "grade": false,
     "grade_id": "cell-48afa45c97dc36fb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "n_samples = 500\n",
    "\n",
    "covariance = [[1, .25],\n",
    "              [.25, 1]]\n",
    "class_one = np.random.multivariate_normal(mean=[5, 10], cov=covariance, size=n_samples)\n",
    "class_one_labels = -np.ones(n_samples)\n",
    "\n",
    "class_two = np.random.multivariate_normal(mean=[0, 5], cov=covariance, size=n_samples)\n",
    "class_two_labels = np.ones(n_samples)\n",
    "\n",
    "features = np.vstack((class_one, class_two))\n",
    "labels = np.hstack((class_one_labels, class_two_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d9b9f61365c63503c48cf55fa0b19624",
     "grade": false,
     "grade_id": "cell-a262f12a83fdbc86",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's see what what our feature vectors look like. We can get statistics (count, mean, std, min, max, 25th percentile value, 50th percentile value, and 75th percentile value) of `feature_1` and `feature_2` separately for data points of each class. For `label == -1`, `feature_1` should lie around value 5 and `feature_2` should lie around value 10 (and standard deviation should be about 1). Similarly for `label == 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "83e8f819da877f345b634fe2d477832e",
     "grade": false,
     "grade_id": "cell-e1b41547fa842508",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('features shape: ', features.shape)\n",
    "print(features.round(3))\n",
    "\n",
    "df = pd.DataFrame(np.vstack([labels, features[:, 0], features[:, 1]]).T, columns=['label', 'feature_1', 'feature_2'])\n",
    "display(df.groupby('label').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a34007278db677f96421947a6f8439e",
     "grade": false,
     "grade_id": "cell-35671efd5ad5d419",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can visualize the features for each class in a 2D scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e1c489a69d59d8c7f38e728e74ce6382",
     "grade": false,
     "grade_id": "cell-ff1f0296d7835ca5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(features[:, 0], features[:, 1],\n",
    "            c=labels, alpha=.6);\n",
    "\n",
    "plt.title(\"Binary labeled data in 2D\", size=15);\n",
    "plt.xlabel(\"Feature 1\", size=13);\n",
    "plt.ylabel(\"Feature 2\", size=13);\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fa4b5588ec2f8d55b16bad0b062ecc6c",
     "grade": false,
     "grade_id": "cell-ff5ae8402f789a19",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In logistic regression, we use _gradient ascent_ to solve for the weight vector that _maximizes_ the (log) likelihood of observing the data. As you have learned so far, this _optimal_ weight vector defines a perpendicular hyperplane that _best_ divides the data points of the two classes.\n",
    "\n",
    "**Equivalently, we can use gradient _descent_ to solve for the weight vector that _minimizes_ the _negative_ log likelihood - refer to Module 3 if you need a review of this derivation!**\n",
    "\n",
    "So, let's continue walking backwards from our goal. Now that we have an artificial dataset, we need to create a logistic regression classifier. For the classifier, we will need to compute the negative log likelihood (modeled using the logistic loss function) and a function to train the minimize the negative log likelihood using gradient descent.\n",
    "\n",
    "The logistic loss uses the sigmoid function, which you will implement first. Next, you will implement $P \\left(y_i | \\mathbf{x}_i \\right)$ using the sigmoid function, followed by the negative log likelihood. You will use these functions in the subsequent projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "86ba54ca7a20269cd878b5dae1e713c0",
     "grade": false,
     "grade_id": "cell-7416e2b0005a62ca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3>Part One: Sigmoid [Graded]</h3>\n",
    "\n",
    "In **`sigmoid`**, implement the sigmoid function: $\\sigma(z)=\\frac{1}{1+e^{-z}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "445f1c3a84d1681aa5ba56ea69336ac9",
     "grade": false,
     "grade_id": "cell-sigmoid",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "    Calculates the sigmoid of z.\n",
    "    \n",
    "    Input:\n",
    "        z: scalar or array of dimension n\n",
    "    \n",
    "    Output:\n",
    "        scalar or array of dimension n\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    return np.divide(1, 1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7b9488af63fdd5d7824d80b60c08b033",
     "grade": false,
     "grade_id": "cell-8a3ba70c3703b8ce",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's plot the sigmoid function for values around 0. The sigmoid function should _plateau_, i.e. output almost a constant value, for negative or positive values of large magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x, y)\n",
    "plt.title('$\\sigma(x)$')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "44bc4f559c4d8b99ac6d7a4068ded524",
     "grade": false,
     "grade_id": "cell-sigmoid_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_sigmoid1():\n",
    "    h = np.random.rand(10) # input is an 10-dimensional array\n",
    "    sgmd1 = sigmoid(h)\n",
    "    return sgmd1.shape == h.shape # output should be a 10-dimensional array\n",
    "\n",
    "def test_sigmoid2():\n",
    "    h = np.random.rand(10) # input is an 10-dimensional array\n",
    "    sgmd1 = sigmoid(h) # compute the sigmoids with your function\n",
    "    sgmd2 = sigmoid_grader(h) # compute the sigmoids with ground truth funcdtion\n",
    "    return (np.linalg.norm(sgmd1 - sgmd2) < 1e-5) # check if they agree\n",
    "\n",
    "def test_sigmoid3():\n",
    "    x = np.random.rand(1) # input is a scalar\n",
    "    sgmd1 = sigmoid(x) # compute the sigmoids with your function\n",
    "    sgmd2 = sigmoid_grader(x) # compute the sigmoids with ground truth function\n",
    "    return (np.linalg.norm(sgmd1 - sgmd2) < 1e-5) # check if they agree\n",
    "\n",
    "def test_sigmoid4():\n",
    "    x = np.array([-1e10,1e10,0]) # three input points: very negative, very positive, and 0\n",
    "    sgmds = sigmoid(x) # compute the sigmoids with your function\n",
    "    truth = np.array([0,1,0.5]) # the truth should be 0, 1, 0.5 exactly\n",
    "    return (np.linalg.norm(sgmds - truth) < 1e-8) # test if this is true\n",
    "\n",
    "\n",
    "runtest(test_sigmoid1, 'test_sigmoid1')\n",
    "runtest(test_sigmoid2, 'test_sigmoid2')\n",
    "runtest(test_sigmoid3, 'test_sigmoid3')\n",
    "runtest(test_sigmoid4, 'test_sigmoid4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "69149486f5bf0a430b79d1d875583152",
     "grade": false,
     "grade_id": "cell-39b725f750b9a36b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Note: you may receive a warning, 'RuntimeWarning: overflow encountered in exp.' This can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ddf70b4e9231faf7566b421f9422745b",
     "grade": true,
     "grade_id": "cell-test_sigmoid1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_sigmoid1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0b762629dfe3eae6588278977b8d6e32",
     "grade": true,
     "grade_id": "cell-test_sigmoid2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_sigmoid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d22b086952b602f24474cc8177816bf7",
     "grade": true,
     "grade_id": "cell-test_sigmoid3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_sigmoid3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f364a5b6aafd26130e1841e43f93cd3",
     "grade": true,
     "grade_id": "cell-cell-test_sigmoid4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_sigmoid4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3826e8a192cca1dfb8ba0947a0c3a73d",
     "grade": false,
     "grade_id": "cell-a2e7bdf679a2c694",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3>Part Two: Implement <code>y_pred</code> [Graded]</h3>\n",
    "\n",
    "Implement the function **`y_pred(X, w)`** that computes $P \\left( y_i = 1 | \\mathbf{x}_i ; \\mathbf{w}, b \\right)$ for each row-vector $\\mathbf{x}_i$ in the matrix `X`. \n",
    "\n",
    "Recall that:\n",
    "$$\n",
    "P \\left( y_i | \\mathbf{x}_i; \\mathbf{w}, b \\right) = \\sigma \\left( y_i \\left( \\mathbf{w}^\\top \\mathbf{x}_i + b \\right) \\right)\n",
    "$$\n",
    "\n",
    "Since `y_pred` calculates the probability of the positive label +1, $\\sigma \\left(y_i \\left( \\mathbf{w}^\\top \\mathbf{x}_i + b \\right) \\right)$ simplifies to $\\sigma \\left( \\mathbf{w}^\\top \\mathbf{x}_i + b \\right)$, which you must output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8fd78d18d36581ea7523375ea4416327",
     "grade": false,
     "grade_id": "cell-ypred",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def y_pred(X, w, b=0):\n",
    "    '''\n",
    "    Calculates the probability of the positive class.\n",
    "    \n",
    "    Input:\n",
    "        X: data matrix of shape nxd\n",
    "        w: d-dimensional vector\n",
    "        b: scalar (optional, default is 0)\n",
    "    \n",
    "    Output:\n",
    "        n-dimensional vector\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    # calculate inner product\n",
    "    z = np.dot(w, X.T) + b\n",
    "    # calculate sigmoid function return\n",
    "    y_predicted = sigmoid(z)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5f0c884bacac030f3817a0efadbceaa5",
     "grade": false,
     "grade_id": "cell-af938b7c2841bef3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's do a sanity check for the `y_pred` function using a small test set. You can do a quick check:\n",
    "> For a data point $i$, whether $P(y_i = 1)$ (`y_pred[i]`) is close to 1 or 0 when $\\mathbf{w}^\\top \\mathbf{x}_i + b$ is greater than 0 or less than 0 respectively.\n",
    "\n",
    "Why does the check work? Recall the output of the sigmoid function for positive and negative values. When the input to sigmoid is large and positive, the output probability is close to 1. And when the input is large and negative, the probability is close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n, d = 5, 3\n",
    "X = np.random.randint(0, 3, (n,d))    # contains multiple observations as rows\n",
    "w = np.random.randint(-3, 3, d)       # this will be our trained vector of coefficients\n",
    "b = 1                                 # this will be our trained offset (or bias) scalar\n",
    "pY = y_pred(X, w, b).round(2)\n",
    "print(f'X = \\n{X}')\n",
    "print(f'w = {w}, b = {b}')\n",
    "print(f'Vector of probabilities of class +1 (conditional on x and w) = {pY}')\n",
    "print(f'Vector of probabilities of class -1 (conditional on x and w) = {1-pY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "914faf01c1cee8422f9f11e63e143f4f",
     "grade": false,
     "grade_id": "cell-ypred-selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_ypred1():\n",
    "    n = 20\n",
    "    d = 5\n",
    "    X = np.random.rand(n,d) # generate n random vectors with d dimensions\n",
    "    w = np.random.rand(5) # define a random weight vector\n",
    "    probs=y_pred(X,w,0) # compute the probabilities of P(y=1|x;w) using your y_pred function\n",
    "    return probs.shape == (n, ) # check if all outputs are >=0 and <=1\n",
    "\n",
    "\n",
    "def test_ypred2():\n",
    "    n = 20\n",
    "    d = 5\n",
    "    X = np.random.rand(n,d) # generate n random vectors with d dimensions\n",
    "    w = np.random.rand(5) # define a random weight vector\n",
    "    probs=y_pred(X, w, 0) # compute the probabilities of P(y=1|x;w) using your y_pred function\n",
    "    return all(probs>=0) and all(probs<=1) # check if all outputs are >=0 and <=1\n",
    "\n",
    "def test_ypred3():\n",
    "    n = 20\n",
    "    d = 5\n",
    "    X = np.random.rand(n,d) # generate n random vectors with d dimensions\n",
    "    w = np.random.rand(5) # define a random weight vector\n",
    "    probs1=y_pred(X, w, 0) # compute the probabilities of P(y=1|x;w) using your y_pred function\n",
    "    probs2=y_pred(X,-w, 0) # compute the probabilities of P(y=1|x;w) using your y_pred function\n",
    "    return np.linalg.norm(probs1+probs2-1)<1e-08 # check if P(y|x;w)+P(y|x;-w)=1\n",
    "\n",
    "\n",
    "\n",
    "def test_ypred4():\n",
    "    X=np.random.rand(25,4) # define random input\n",
    "    w=np.array([1,0,0,0]) # all-zeros weight vector\n",
    "    prob=y_pred(X, w, 0) # compute P(y|X;w)\n",
    "    truth=sigmoid(X[:,0]) # should simply be the sigmoid of the first feature\n",
    "    return np.linalg.norm(prob-truth)<1e-08 # see if they match\n",
    "\n",
    "\n",
    "def test_ypred5(): \n",
    "    X=np.array([[0.61793598, 0.09367891], # define 3 inputs (2D)\n",
    "               [0.79447745, 0.98605996],\n",
    "               [0.53679997, 0.4253885 ]])\n",
    "    w=np.array([0.9822789 , 0.16017851]); # define weight vector\n",
    "    prob=y_pred(X, w, 3) # compute P(y|X;w)\n",
    "    truth=np.array([0.97396645,0.98089179,0.97328431]) # this is the grount truth\n",
    "    return np.linalg.norm(prob-truth)<1e-08 # see if they match\n",
    "\n",
    "runtest(test_ypred1, 'test_ypred1')\n",
    "runtest(test_ypred2, 'test_ypred2')\n",
    "runtest(test_ypred3, 'test_ypred3')\n",
    "runtest(test_ypred4, 'test_ypred4')\n",
    "runtest(test_ypred5, 'test_ypred5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "478127a53656b7f433ea2f00eb38a2ee",
     "grade": true,
     "grade_id": "cell-test_ypred1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_ypred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "516e14d33938f7915273495475df85ff",
     "grade": true,
     "grade_id": "cell-test_ypred2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_ypred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cf7c9485768fa22295c435fc2c4985d2",
     "grade": true,
     "grade_id": "cell-test_ypred3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_ypred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "07d0edae102b006186dee458124f4507",
     "grade": true,
     "grade_id": "cell-test_ypred4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_ypred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6d37a4b9eedef4150991da4d8864314a",
     "grade": true,
     "grade_id": "cell-test_ypred5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_ypred5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "03b6fb1151c8ae6f0ad9bac238e7c9c0",
     "grade": false,
     "grade_id": "cell-d78742f7568a5421",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3>Part Three: Implement <code>log_loss</code> [Graded]</h3>\n",
    "\n",
    "Now you will compute the negative log likelihood in **`log_loss`**. You are given the label vector `y` and the data matrix `X` with `n` data points as row vectors. The negative log likelihood ($NLL$) is defined as follows:\n",
    "\n",
    "$$\n",
    "NLL = -\\log P(\\mathbf{y} \\vert \\mathbf{X}; \\mathbf{w}, b) = -\\log \\prod_{i=1}^n P \\left(y_i | \\mathbf{x}_i; \\mathbf{w}, b \\right) = -\\sum_{i=1}^n \\log P\\left(y_i | \\mathbf{x}_i; \\mathbf{w}, b \\right) = -\\sum_{i=1}^n \\log \\sigma \\left( y_i \\left(\\mathbf{w}^\\top \\mathbf{x}_i + b \\right) \\right).\n",
    "$$\n",
    "\n",
    "While we only computed the probability of a positive label in `y_pred`, now we will account for the actual $y$ value. You can use your implementation of `y_pred` for `log_loss` or reimplement to account for the $y$ -- the latter yields cleaner code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define y_pred_neg to make things easier\n",
    "def y_pred_neg(X, w, b=0):\n",
    "    # YOUR CODE HERE\n",
    "    # calculate inner product\n",
    "    z = np.dot(w, X.T) + b\n",
    "    # calculate sigmoid function return\n",
    "    y_predicted = sigmoid(-z)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0f8f3d190144a6f1e28768343b0fb1b7",
     "grade": false,
     "grade_id": "cell-log_loss",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def log_loss(X, y, w, b=0):\n",
    "    '''\n",
    "    Calculates the negative log likelihood for dataset (X, y) using the weight vector w and bias b.\n",
    "    \n",
    "    Input:\n",
    "        X: data matrix of shape nxd\n",
    "        y: n-dimensional vector of labels (+1 or -1)\n",
    "        w: d-dimensional vector\n",
    "        b: scalar (optional, default is 0)\n",
    "    \n",
    "    Output:\n",
    "        scalar\n",
    "    '''\n",
    "    assert np.sum(np.abs(y)) == len(y) # check if all labels in y are either +1 or -1\n",
    "    # YOUR CODE HERE\n",
    "    # define vector that will be filled with log y prediction\n",
    "    y_pred_log = np.zeros(y.size)\n",
    "    # avoid for loop and get indices for pos and neg y labels\n",
    "    y_pos_idx = y > 0\n",
    "    y_neg_idx = y < 0\n",
    "    # calculate y predicted for positive and negative y labels and take logs\n",
    "    y_pred_log[y_pos_idx] = np.log(y_pred(X, w, b)[y_pos_idx])\n",
    "    y_pred_log[y_neg_idx] = np.log(y_pred_neg(X, w, b)[y_neg_idx])\n",
    "    # sum over log\n",
    "    nll = (-1) * np.sum(y_pred_log)\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "38da95c4265815b35d8c1fa6fba00d71",
     "grade": false,
     "grade_id": "cell-log_loss-selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_logloss1():\n",
    "    X = np.random.rand(25,5) # generate n random vectors with d dimensions\n",
    "    w = np.random.rand(5) # define a random weight vector\n",
    "    b = np.random.rand(1) # define a bias\n",
    "    y = np.ones(25) # set labels all-(+1)\n",
    "    ll=log_loss(X,y,w, b) # compute the probabilities of P(y=1|x;w) using your y_pred function\n",
    "    # if labels are all-ones function becomes simply the sum of log of y_pred\n",
    "    return np.isscalar(ll) # check whether the output is a scalar\n",
    "\n",
    "def test_logloss2():\n",
    "    X = np.random.rand(25,5) # generate n random vectors with d dimensions\n",
    "    w = np.random.rand(5) # define a random weight vector\n",
    "    b = np.random.rand(1) # define a bias\n",
    "    y = np.ones(25) # set labels all-(+1)\n",
    "    ll=log_loss(X,y,w, b) # compute the probabilities of P(y=1|x;w) using your y_pred function\n",
    "    ll2=-np.sum(np.log(y_pred(X, w, b))) # if labels are all-ones function becomes simply the sum of log of y_pred\n",
    "    return np.linalg.norm(ll-ll2)<1e-05\n",
    "\n",
    "def test_logloss3():\n",
    "    X = np.random.rand(25,5) # generate n random vectors with d dimensions\n",
    "    w = np.random.rand(5) # define a random weight vector\n",
    "    b = np.random.rand(1) # define a bias\n",
    "    y = -np.ones(25) # set labels all-(-1)\n",
    "    ll=log_loss(X,y,w,b) # compute the probabilities of P(y=1|x;w) using your y_pred function\n",
    "    ll2=-np.sum(np.log(1-y_pred(X,w, b))) # if labels are all-ones function becomes simply the sum of log of 1-y_pred\n",
    "    return np.linalg.norm(ll-ll2)<1e-05\n",
    "\n",
    "def test_logloss4():\n",
    "    X = np.random.rand(20,5) # generate n random vectors with d dimensions\n",
    "    w = np.array([0,0,0,0,0]) # define an all-zeros weight vector\n",
    "    y = (np.random.rand(20)>0.5)*2-1; # define n random labels (+1 or -1)\n",
    "    ll=log_loss(X,y,w,0) # compute the probabilities of P(y=1|x;w) using your y_pred function\n",
    "    # the log-likelihood for each of the 20 examples should be exactly 0.5:\n",
    "    return np.linalg.norm(ll+20*np.log(0.5))<1e-08 \n",
    "\n",
    "def test_logloss5():\n",
    "    X = np.random.rand(500,15) # generate n random vectors with d dimensions\n",
    "    w = np.random.rand(15) # define a random weight vector\n",
    "    b = np.random.rand(1) # define a bias\n",
    "    y = (np.random.rand(500)>0.5)*2-1; # define n random labels (+1 or -1)\n",
    "    ll=log_loss(X,y,w,b) # compute the probabilities of P(y=1|x;w) using your y_pred function\n",
    "    ll2=log_loss_grader(X,y,w,b) # compute the probabilities of P(y=1|x;w) using your y_pred function\n",
    "    return np.linalg.norm(ll-ll2)<1e-05\n",
    "\n",
    "runtest(test_logloss1, 'test_logloss1')\n",
    "runtest(test_logloss2, 'test_logloss2')\n",
    "runtest(test_logloss3, 'test_logloss3')\n",
    "runtest(test_logloss4, 'test_logloss4')\n",
    "runtest(test_logloss5, 'test_logloss5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "63b414e5d8c658966558e0f8ee288bfd",
     "grade": true,
     "grade_id": "cell-test_logloss1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_logloss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "edd4b4c45cea36f6fcd870f812a2ae4f",
     "grade": true,
     "grade_id": "cell-test_logloss2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_logloss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a65c1c2982c7804c0b8989fe74c31902",
     "grade": true,
     "grade_id": "cell-test_logloss3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_logloss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b35421e2c2fe785673e30f59124dcf43",
     "grade": true,
     "grade_id": "cell-test_logloss4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_logloss4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c9e5d4bd521cd593729b7620a93f46d2",
     "grade": true,
     "grade_id": "cell-test_logloss5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test_logloss5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}